# @package _global_

defaults:
  - _self_
  - /data: cifar10

trainer:
  # ===== Base Trainer =====
  _target_: stable_ssl.JointEmbeddingTrainer

  # ===== loss Parameters =====
  loss:
    _target_: stable_ssl.BarlowTwinsLoss

  # ===== Data Parameters =====
  data:
    _num_classes: 10
    _num_samples: 50000
    train: # training dataset as indicated by name
      _target_: torch.utils.data.DataLoader
      batch_size: 256
      drop_last: True
      shuffle: True
      num_workers: 4
      dataset:
        _target_: torchvision.datasets.CIFAR10
        root: ~/data
        train: True
        download: True
        transform:
          _target_: stable_ssl.data.MultiViewSampler
          transforms:
            - _target_: torchvision.transforms.v2.Compose
              transforms:
                - _target_: torchvision.transforms.v2.RandomResizedCrop
                  size: 32
                  scale:
                    - 0.2
                    - 1.0
                - _target_: torchvision.transforms.v2.RandomHorizontalFlip
                  p: 0.5
                - _target_: torchvision.transforms.v2.RandomApply
                  p: 0.8
                  transforms:
                    - {
                        _target_: torchvision.transforms.v2.ColorJitter,
                        brightness: 0.8,
                        contrast: 0.8,
                        saturation: 0.8,
                        hue: 0.2,
                      }
                - _target_: stable_ssl.data.augmentations.GaussianBlur
                  sigma:
                    - 0.1
                    - 2.0
                - _target_: torchvision.transforms.v2.ToImage
                - _target_: torchvision.transforms.v2.ToDtype
                  dtype:
                    _target_: stable_ssl.utils.str_to_dtype
                    _args_: [float32]
                  scale: True
            - ${trainer.data.train.dataset.transform.transforms.0}
    test: # can be any name
      _target_: torch.utils.data.DataLoader
      batch_size: 256
      num_workers: ${trainer.data.train.num_workers}
      dataset:
        _target_: torchvision.datasets.CIFAR10
        train: False
        root: ~/data
        transform:
          _target_: torchvision.transforms.v2.Compose
          transforms:
            - _target_: torchvision.transforms.v2.ToImage
            - _target_: torchvision.transforms.v2.ToDtype
              dtype:
                _target_: stable_ssl.utils.str_to_dtype
                _args_: [float32]
              scale: True

  # ===== Module Parameters =====
  module:
    backbone:
      _target_: stable_ssl.modules.load_backbone
      name: resnet18
      low_resolution: True
      num_classes: null
    projector:
      _target_: torch.nn.Sequential
      _args_:
        - _target_: torch.nn.Linear
          in_features: 512
          out_features: 2048
          bias: False
        - _target_: torch.nn.BatchNorm1d
          num_features: ${trainer.module.projector._args_.0.out_features}
        - _target_: torch.nn.ReLU
        - _target_: torch.nn.Linear
          in_features: ${trainer.module.projector._args_.0.out_features}
          out_features: 128
          bias: False
        - _target_: torch.nn.BatchNorm1d
          num_features: ${trainer.module.projector._args_.3.out_features}
    projector_classifier:
      _target_: torch.nn.Linear
      in_features: 128
      out_features: ${trainer.data._num_classes}
    backbone_classifier:
      _target_: torch.nn.Linear
      in_features: 512
      out_features: ${trainer.data._num_classes}

  # ===== Optim Parameters =====
  optim:
    epochs: 1000
    optimizer:
      _target_: stable_ssl.optimizers.LARS
      _partial_: True
      lr: 5
      weight_decay: 1e-6
    scheduler:
      _target_: stable_ssl.schedulers.LinearWarmupCosineAnnealing
      _partial_: True
      total_steps: ${eval:'${trainer.optim.epochs} * ${trainer.data._num_samples} // ${trainer.data.train.batch_size}'}
